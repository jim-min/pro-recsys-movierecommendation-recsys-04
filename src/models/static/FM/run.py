import os
import json
import argparse
import torch
import pandas as pd
import numpy as np

from data_utils import (
    read_interactions,
    encode_ids,
    build_user_item_matrix,
    train_valid_split_random,
    set_seed
)
from model import FactorizationMachine # ë„¤ê°€ ì •ì˜í•œ FM ëª¨ë¸ í´ë˜ìŠ¤
from trainer import FMTrainer
from recommend import recommend_topk

def prepare_item_features_from_json(json_path, it2i, num_users, num_items):
    """
    Ml_item2attributes.json íŒŒì¼ì„ ì½ì–´ì„œ FMìš© ì†ì„± í–‰ë ¬ê³¼ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•¨.
    ëª¨ë“  ì†ì„± ì¸ë±ìŠ¤ì—ëŠ” (num_users + num_items)ë§Œí¼ì˜ Offsetì„ ë”í•´ ì¸ë±ìŠ¤ ê²¹ì¹¨ì„ ë°©ì§€í•¨.
    """
    if not os.path.exists(json_path):
        print(f"âš ï¸ {json_path}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì†ì„± ì—†ì´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        return torch.zeros((num_items, 1), dtype=torch.long), torch.zeros((num_items, 1)), 0

    with open(json_path, 'r') as f:
        item2attr = json.load(f)

    # 1. ì†ì„±ì˜ ì „ì²´ ì¢…ë¥˜ ìˆ˜ íŒŒì•…
    all_attrs = []
    for attrs in item2attr.values():
        all_attrs.extend(attrs)
    
    num_unique_attrs = max(all_attrs) + 1 if all_attrs else 0
    # ì•„ì´í…œë‹¹ ìµœëŒ€ ì†ì„± ê°œìˆ˜ íŒŒì•… (Paddingìš©)
    max_attrs = max(len(v) for v in item2attr.values()) if item2attr else 1

    # 2. ê²°ê³¼ í–‰ë ¬ ì´ˆê¸°í™”
    item_attr_mat = np.zeros((num_items, max_attrs), dtype=np.int64)
    item_attr_mask = np.zeros((num_items, max_attrs), dtype=np.float32)

    # 3. ì†ì„± ì¸ë±ìŠ¤ì— Offset ì ìš©
    # User(0~U-1) + Item(U~U+I-1) + Attr(U+I~...)
    attr_offset = num_users + num_items

    for item_id_str, attrs in item2attr.items():
        item_id = int(item_id_str)
        if item_id in it2i:
            idx = it2i[item_id]
            for i, a in enumerate(attrs):
                item_attr_mat[idx, i] = a + attr_offset
                item_attr_mask[idx, i] = 1.0

    print(f"âœ… ì†ì„± ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì¢…ë¥˜ {num_unique_attrs}ê°œ, ìµœëŒ€ ì†ì„± ìˆ˜ {max_attrs}ê°œ")
    return torch.tensor(item_attr_mat), torch.tensor(item_attr_mask), num_unique_attrs

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", default="/data/ephemeral/home/Seung/data/train/")
    parser.add_argument("--output_dir", default="/data/ephemeral/home/Seung/output/FM/")
    parser.add_argument("--epochs", type=int, default=100)
    parser.add_argument("--batch_size", type=int, default=2048)
    parser.add_argument("--steps_per_epoch", type=int, default=500)
    parser.add_argument("--embed_dim", type=int, default=16)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--weight_decay", type=float, default=1e-5)
    parser.add_argument("--topk", type=int, default=10)
    parser.add_argument("--valid_ratio", type=float, default=0.1)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--early_stop_patience", type=int, default=15)
    args = parser.parse_args()

    set_seed(args.seed)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    os.makedirs(args.output_dir, exist_ok=True)
    ckpt_path = os.path.join(args.output_dir, "best_fm.pt")

    # [1] ë°ì´í„° ë¡œë“œ ë° ì¸ì½”ë”©
    df = read_interactions(args.data_dir)
    df_enc, u2i, i2u, it2i, i2it = encode_ids(df)
    num_users, num_items = len(u2i), len(it2i)

    # [2] ê²€ì¦ ë°ì´í„° ë¶„ë¦¬ (ëŒ€íšŒ ê³µì‹ Recall ì¸¡ì •ìš©)
    train_df, valid_gt = train_valid_split_random(df_enc, num_users, valid_ratio=args.valid_ratio, seed=args.seed)
    train_mat = build_user_item_matrix(train_df, num_users, num_items)

    # [3] JSONì—ì„œ ì•„ì´í…œ ì†ì„± ë¡œë“œ ë° Offset ì ìš©
    json_path = os.path.join(args.data_dir, "Ml_item2attributes.json")
    item_attr_mat, item_attr_mask, num_unique_attrs = prepare_item_features_from_json(
        json_path, it2i, num_users, num_items
    )
    
    # ì „ì²´ í”¼ì²˜ ìˆ˜ ê³„ì‚° (User ID + Item ID + Attribute IDs)
    total_features = num_users + num_items + num_unique_attrs

    # [4] ëª¨ë¸ ì´ˆê¸°í™”
    model = FactorizationMachine(total_features, args.embed_dim)
    
    # [5] íŠ¸ë ˆì´ë„ˆ ì„¤ì • (Recall ê¸°ë°˜ Early Stopping ë‚´ì¥)
    trainer = FMTrainer(
        model=model,
        train_mat=train_mat,
        valid_user_pos=valid_gt,
        num_items=num_items,
        item_attr_mat=item_attr_mat,
        item_attr_mask=item_attr_mask,
        user_offset=0,
        item_offset=num_users,
        lr=args.lr,
        weight_decay=args.weight_decay,
        device=device,
        ckpt_path=ckpt_path,
        early_stop_patience=args.early_stop_patience
    )

    # [6] í•™ìŠµ ìˆ˜í–‰
    print("ğŸš€ FM í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    trainer.train(epochs=args.epochs, batch_size=args.batch_size, 
                  steps_per_epoch=args.steps_per_epoch, topk=args.topk)

    # [7] ìµœì  ëª¨ë¸ ë¡œë“œ ë° ìµœì¢… ì¶”ì²œ ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
    print("ğŸ ìµœì¢… ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    best_state = torch.load(ckpt_path)
    model.load_state_dict(best_state)
    
    # recommend_topkëŠ” ì´ì œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‘ë™í•˜ì—¬ ë©”ëª¨ë¦¬ì™€ ì†ë„ë¥¼ ëª¨ë‘ ì¡ìŒ
    rec = recommend_topk(
        model=model,
        train_mat=train_mat,
        item_attr_mat=item_attr_mat,
        item_attr_mask=item_attr_mask,
        topk=args.topk,
        device=device,
        user_offset=0,
        item_offset=num_users,
        user_batch_size=256 # ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¼ ì¡°ì ˆ ê°€ëŠ¥
    )

    # [8] submission.csv ì €ì¥
    rows = []
    for u_idx in range(num_users):
        for it_idx in rec[u_idx]:
            rows.append((i2u[u_idx], i2it[int(it_idx)]))
            
    pd.DataFrame(rows, columns=["user", "item"]).to_csv(
        os.path.join(args.output_dir, "submission.csv"), index=False
    )
    print(f"âœ… ì œì¶œ íŒŒì¼ì´ {args.output_dir}ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()